{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2964963a",
   "metadata": {},
   "source": [
    "# Фреймворк PyTorch для разработки искусственных нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f0f08",
   "metadata": {},
   "source": [
    "## Урок 9. Трансформер"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c6fdaa",
   "metadata": {},
   "source": [
    "### Практическое задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352e4725",
   "metadata": {},
   "source": [
    "1. Возьмите готовую модель из https://huggingface.co/models для классификации сентимента текста.\n",
    "2. Сделайте предсказания на всем df_val. Посчитайте метрику качества.\n",
    "3. Дообучите эту модель на df_train. Посчитайте метрику качества на df_val.\n",
    "\n",
    "Данные на google drive: https://drive.google.com/file/d/1Mev_EEput0LlBj8MDHIJkBtahlJ6J901"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b64e54",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c20958",
   "metadata": {},
   "source": [
    "#### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "99bbeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fc1a29",
   "metadata": {},
   "source": [
    "#### Настройки проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d4df6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Случайное зерно.\n",
    "GLOBAL__RANDOM_STATE = 0\n",
    "\n",
    "# Выбор устройства.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Путь к данным.\n",
    "PATH__DATA_TRAIN = r'train.csv'\n",
    "PATH__DATA_VAL = r'val.csv'\n",
    "\n",
    "# Выбор устройства.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fc37d8",
   "metadata": {},
   "source": [
    "#### 1. Выбор готовой модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ddcce",
   "metadata": {},
   "source": [
    "Для выбора модели использовались следующие критерии:\n",
    "\n",
    "    Язык: русский\n",
    "    Библиотека: PyTorch\n",
    "    Задача: классификация текста\n",
    "\n",
    "https://huggingface.co/models?language=ru&library=pytorch&pipeline_tag=text-classification&sort=downloads\n",
    "\n",
    "В результате была выбрана модель `SkolkovoInstitute/russian_toxicity_classifier`, построенная на основе классической модели `Bert`.\n",
    "\n",
    "https://huggingface.co/SkolkovoInstitute/russian_toxicity_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "622be591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 172 ms\n",
      "Wall time: 2.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Загрузка токенайзера модели.\n",
    "tokenizer = BertTokenizer.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "578611a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.97 s\n",
      "Wall time: 2.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Загрузка модели и весов.\n",
    "model = BertForSequenceClassification.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dfb2942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 4.0289, -3.7206]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка работы модели на фразе без оскорбления.\n",
    "batch = tokenizer.encode('ты супер', return_tensors='pt')\n",
    "model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b0af17f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-2.1764,  1.0085]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка работы модели на фразе с оскорблением.\n",
    "batch = tokenizer.encode('ты дурак', return_tensors='pt')\n",
    "model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c98362d",
   "metadata": {},
   "source": [
    "Модель принимает на вход ембеддинг собственного токенайзера, а возвращает тензор с двумя значениями.\n",
    "\n",
    "У модели отсутствует сопроводительная документация, но тестирование показало, что значения тензора меняют знак в зависимости от эмоциональной окраски.\n",
    "\n",
    "Выполним предсказание на валидационной выборке чтобы оценить качество."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3263ea",
   "metadata": {},
   "source": [
    "#### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f1447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка обучающей выборки.\n",
    "df_train = pd.read_csv(PATH__DATA_TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22f98f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  class\n",
       "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
       "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
       "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
       "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
       "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка: вывод первых пяти строк обучающей выборки.\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59c07296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс датасета.\n",
    "class TwitterDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, txts, labels):\n",
    "        self._labels = labels\n",
    "        \n",
    "        self.tokenizer = BertTokenizer.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
    "        self._txts = [\n",
    "            self.tokenizer.encode(\n",
    "                text,\n",
    "                padding='max_length',\n",
    "                max_length=10,\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )[0] for text in txts\n",
    "        ]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self._txts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self._txts[index], self._labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a495bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 50.3 s\n",
      "Wall time: 52.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Подготовка обучающего датасета.\n",
    "ds_train = TwitterDataset(df_train['text'], df_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9ad6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка обучающего загрузчика.\n",
    "dl_train = DataLoader(ds_train, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8fa643d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность тензора объекта:\ttorch.Size([10])\n",
      "Тензор:\n",
      "\ttensor([  101,   108,   168,   186, 12392,   171, 12642, 15113,  4135,   102])\n",
      "Размерность тензора классов:\ttorch.Size([64])\n",
      "Тензор классов:\n",
      "\ttensor([0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Проверка обучающего загрузчика.\n",
    "for x, y in dl_train:\n",
    "    print(f'Размерность тензора объекта:\\t{x[0].shape}')\n",
    "    print(f'Тензор:\\n\\t{x[0]}')\n",
    "    print(f'Размерность тензора классов:\\t{y.shape}')\n",
    "    print(f'Тензор классов:\\n\\t{y}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaf009d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка валидационной выборки.\n",
    "df_val = pd.read_csv(PATH__DATA_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c14a81da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>181467</td>\n",
       "      <td>RT @TukvaSociopat: Максимальный репост! ))) #є...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181468</td>\n",
       "      <td>чтоб у меня з.п. ежегодно индексировали на инд...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181469</td>\n",
       "      <td>@chilyandlime нехуя мне не хорошо !!! :((((</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>181470</td>\n",
       "      <td>@inafish нее , когда ногами ахахах когда?ахаха...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>181471</td>\n",
       "      <td>Хочу сделать как лучше,  а получаю как всегда. :(</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  class\n",
       "0  181467  RT @TukvaSociopat: Максимальный репост! ))) #є...      1\n",
       "1  181468  чтоб у меня з.п. ежегодно индексировали на инд...      0\n",
       "2  181469        @chilyandlime нехуя мне не хорошо !!! :((((      0\n",
       "3  181470  @inafish нее , когда ногами ахахах когда?ахаха...      0\n",
       "4  181471  Хочу сделать как лучше,  а получаю как всегда. :(      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка: вывод первых пяти строк валидационной выборки.\n",
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "860901fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 7.08 s\n",
      "Wall time: 8.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Подготовка валидационного датасета.\n",
    "ds_val = TwitterDataset(df_val['text'], df_val['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "796a2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка валидационного загрузчика.\n",
    "dl_val = DataLoader(ds_val, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05016529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность тензора объекта:\ttorch.Size([10])\n",
      "Тензор:\n",
      "\ttensor([  101,   168, 10637, 11745, 10855,   267,   230, 16781, 21408,   102])\n",
      "Размерность тензора классов:\ttorch.Size([64])\n",
      "Тензор классов:\n",
      "\ttensor([0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Проверка валидационного загрузчика.\n",
    "for x, y in dl_val:\n",
    "    print(f'Размерность тензора объекта:\\t{x[0].shape}')\n",
    "    print(f'Тензор:\\n\\t{x[0]}')\n",
    "    print(f'Размерность тензора классов:\\t{y.shape}')\n",
    "    print(f'Тензор классов:\\n\\t{y}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cdf38b",
   "metadata": {},
   "source": [
    "#### Постороение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7e2a51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс модели.\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bert(x).logits\n",
    "        x = self.sigm(x).argmax(dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ec04f3",
   "metadata": {},
   "source": [
    "#### 2. Предсказание на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "429fe195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Иницализация модели.\n",
    "model = BertClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bda15e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertClassifier(\n",
      "  (bert): BertForSequenceClassification(\n",
      "    (bert): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (1): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (2): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (3): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (4): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (5): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (6): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (7): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (8): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (9): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (10): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (11): BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      "  )\n",
      "  (sigm): Sigmoid()\n",
      ")\n",
      "Parameters full train: 177854978\n"
     ]
    }
   ],
   "source": [
    "# Вывод информации о модели.\n",
    "print(model)\n",
    "print(\"Parameters full train:\", sum([param.nelement() for param in model.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7628ae9a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 355/355 [01:37<00:00,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12min 16s\n",
      "Wall time: 1min 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Списки для истинного и спрогнозированного класса объектов.\n",
    "list_y_true = []\n",
    "list_y_pred = []\n",
    "\n",
    "# Прогноз на валидационной выборке.\n",
    "for x, y in tqdm(dl_val):\n",
    "    y_pred = model.forward(x)\n",
    "    \n",
    "    list_y_true += [*y.numpy()]\n",
    "    list_y_pred += [*y_pred.numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0c435e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.92      0.64     11234\n",
      "           1       0.43      0.06      0.10     11449\n",
      "\n",
      "    accuracy                           0.49     22683\n",
      "   macro avg       0.46      0.49      0.37     22683\n",
      "weighted avg       0.46      0.49      0.37     22683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Вывод метрик качества.\n",
    "print(classification_report(y_true=list_y_true, y_pred=list_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0a1092",
   "metadata": {},
   "source": [
    "Исходная модель крайне плохо справилась с одним из классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323cd65c",
   "metadata": {},
   "source": [
    "#### 3. Дообучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "79224659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс модели.\n",
    "class BertClassifier_v2(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = BertForSequenceClassification.from_pretrained('SkolkovoInstitute/russian_toxicity_classifier')\n",
    "        self.bert.requires_grad_(False)\n",
    "        \n",
    "        self.linear_1 = nn.Linear(in_features=2, out_features=20)\n",
    "        self.drop_out_1 = nn.Dropout1d(p=0.1)\n",
    "        self.batch_norm_1 = nn.BatchNorm1d(num_features=20)\n",
    "        self.leaky_relu_1 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        \n",
    "        self.linear_2 = nn.Linear(in_features=20, out_features=20)\n",
    "        self.drop_out_2 = nn.Dropout1d(p=0.1)\n",
    "        self.batch_norm_2 = nn.BatchNorm1d(num_features=20)\n",
    "        self.leaky_relu_2 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        \n",
    "        self.linear_3 = nn.Linear(in_features=20, out_features=10)\n",
    "        self.leaky_relu_3 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        \n",
    "        self.linear_4 = nn.Linear(in_features=10, out_features=5)\n",
    "        self.leaky_relu_4 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        \n",
    "        self.linear_5 = nn.Linear(in_features=5, out_features=1)\n",
    "        self.leaky_relu_5 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        \n",
    "        self.sigm = nn.Sigmoid()\n",
    "    \n",
    "\n",
    "    def forward(self, x, threshold=0.5):\n",
    "        x = self.bert(x).logits\n",
    "        \n",
    "        x = self.linear_1(x)\n",
    "        x = self.drop_out_1(x)\n",
    "        x = self.batch_norm_1(x)\n",
    "        x = self.leaky_relu_1(x)\n",
    "        \n",
    "        x = self.linear_2(x)\n",
    "        x = self.drop_out_2(x)\n",
    "        x = self.batch_norm_2(x)\n",
    "        x = self.leaky_relu_2(x)\n",
    "        \n",
    "        x = self.linear_3(x)\n",
    "        x = self.leaky_relu_3(x)\n",
    "        \n",
    "        x = self.linear_4(x)\n",
    "        x = self.leaky_relu_4(x)\n",
    "        \n",
    "        x = self.linear_5(x)\n",
    "        x = self.leaky_relu_5(x)\n",
    "        \n",
    "        x = self.sigm(x)\n",
    "        \n",
    "        return (x > threshold).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "679039f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Иницализация модели.\n",
    "model_v2 = BertClassifier_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "436a63bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters full train:\t 177855809\n",
      "Parameters level 1:\t 60\n",
      "Parameters level 2:\t 420\n",
      "Parameters level 3:\t 210\n",
      "Parameters level 4:\t 55\n",
      "Parameters level 5:\t 6\n"
     ]
    }
   ],
   "source": [
    "# Вывод информации о параметрах.\n",
    "print(\"Parameters full train:\\t\", sum([param.nelement() for param in model_v2.parameters()]))\n",
    "print(\"Parameters level 1:\\t\", sum([param.nelement() for param in model_v2.linear_1.parameters()]))\n",
    "print(\"Parameters level 2:\\t\", sum([param.nelement() for param in model_v2.linear_2.parameters()]))\n",
    "print(\"Parameters level 3:\\t\", sum([param.nelement() for param in model_v2.linear_3.parameters()]))\n",
    "print(\"Parameters level 4:\\t\", sum([param.nelement() for param in model_v2.linear_4.parameters()]))\n",
    "print(\"Parameters level 5:\\t\", sum([param.nelement() for param in model_v2.linear_5.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "49b67636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отключение обучения всех параметров.\n",
    "for param in model_v2.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "089745cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение первого дополнительного слоя.\n",
    "for param in model_v2.linear_1.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "dc181004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение второго дополнительного слоя.\n",
    "for param in model_v2.linear_2.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9d376229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение третьего дополнительного слоя.\n",
    "for param in model_v2.linear_3.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8c7e2ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение четвёртого дополнительного слоя.\n",
    "for param in model_v2.linear_4.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "829b6b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение пятого дополнительного слоя.\n",
    "for param in model_v2.linear_5.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b67b7148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция потерь.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Оптимизатор.\n",
    "optimizer = Adam(model_v2.parameters(), lr=0.001)  # полное обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "58aaed88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                    | 0/2836 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [194], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     total_acc_train \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m acc\n\u001b[0;32m     15\u001b[0m     model_v2\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mbatch_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     19\u001b[0m model_v2\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# Обучение модели на одной эпохе.\n",
    "for epoch_num in range(1):\n",
    "    total_acc_train = 0\n",
    "    total_loss_train = 0\n",
    "\n",
    "    model.train()\n",
    "    for train_input, train_label in tqdm(dl_train):\n",
    "        output = model_v2(train_input)\n",
    "                \n",
    "        batch_loss = criterion(output.float().reshape(1, -1), train_label.float().reshape(1, -1))\n",
    "        total_loss_train += batch_loss.item()\n",
    "                \n",
    "        acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "        total_acc_train += acc\n",
    "\n",
    "        model_v2.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "    model_v2.eval()\n",
    "    total_loss_val, total_acc_val = 0.0, 0.0\n",
    "    \n",
    "    for val_input, val_label in valid_loader:\n",
    "\n",
    "        output = model_v2(val_input)\n",
    "\n",
    "        batch_loss = criterion(output.float().reshape(1, -1), val_label.float().reshape(1, -1))\n",
    "        total_loss_val += batch_loss.item()\n",
    "                    \n",
    "        acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "        total_acc_val += acc\n",
    "            \n",
    "    print(\n",
    "        f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_dataset): .3f} \\\n",
    "        | Train Accuracy: {total_acc_train / len(train_dataset): .3f} \\\n",
    "        | Val Loss: {total_loss_val / len(valid_dataset): .3f} \\\n",
    "        | Val Accuracy: {total_acc_val / len(valid_dataset): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd6817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Списки для истинного и спрогнозированного класса объектов.\n",
    "list_y_true = []\n",
    "list_y_pred = []\n",
    "\n",
    "# Прогноз на валидационной выборке.\n",
    "for x, y in tqdm(dl_val):\n",
    "    y_pred = model_v2.forward(x)\n",
    "    \n",
    "    list_y_true += [*y.numpy()]\n",
    "    list_y_pred += [*y_pred.numpy().reshape(1, -1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7890a4be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "365px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
