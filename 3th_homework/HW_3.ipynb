{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50862cb7",
   "metadata": {},
   "source": [
    "# Фреймворк PyTorch для разработки искусственных нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35167d81",
   "metadata": {},
   "source": [
    "## Урок 3. Dataset, Dataloader, BatchNorm, Dropout, Оптимизация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c8513",
   "metadata": {},
   "source": [
    "### Практическое задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5836be",
   "metadata": {},
   "source": [
    "Будем практиковаться на датасете недвижимости (sklearn.datasets.fetch_california_housing)\n",
    "\n",
    "Ваша задача:\n",
    "1. Создать Dataset для загрузки данных\n",
    "2. Обернуть его в Dataloader\n",
    "3. Написать архитектуру сети, которая предсказывает стоимость недвижимости. Сеть должна включать BatchNorm слои и Dropout (или НЕ включать, но нужно обосновать)\n",
    "4. Сравните сходимость Adam, RMSProp и SGD, сделайте вывод по качеству работы модели\n",
    "\n",
    "train-test разделение нужно сделать с помощью sklearn random_state=13, test_size = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5b22a1",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb13e91e",
   "metadata": {},
   "source": [
    "#### Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb0f577b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import Dataset \n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "from torch import nn\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.optim import RMSprop\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5360548e",
   "metadata": {},
   "source": [
    "#### 1. Создание Dataset для загрузки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39a1177d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20640, 8), (20640,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка датасета.\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "# Проверка: вывод размерностей признаков и целевой переменной.\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4d99357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15480, 8), (5160, 8), (15480,), (5160,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Разбиение данных на обучающую и тестовую выборки.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=13)\n",
    "\n",
    "# Проверка: вывод размерностей.\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ea9d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для представления данных.\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y=None, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.transform is not None and self.y is not None:\n",
    "            return self.transform(self.X[index]), self.y[index]\n",
    "        elif self.transform is not None and self.y is None:\n",
    "            return self.transform(self.X[index])\n",
    "        elif self.transform is None and self.y is not None:\n",
    "            return self.X[index], self.y[index]\n",
    "        elif self.transform is None and self.y is None:\n",
    "            return self.X[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "86f1508a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина:\n",
      "\t15480\n",
      "\n",
      "Первый элемент:\n",
      "\t(array([ 3.51740000e+00,  3.60000000e+01,  4.54794521e+00,  1.09436834e+00,\n",
      "        1.35700000e+03,  2.06544901e+00,  3.42100000e+01, -1.18230000e+02]), 2.68)\n"
     ]
    }
   ],
   "source": [
    "# Представление обучающей выборки в виде класса.\n",
    "dataset_train = MyDataset(X_train, y_train)\n",
    "\n",
    "# Проверка: вывод длины.\n",
    "print(f'Длина:\\n\\t{dataset_train.__len__()}')\n",
    "\n",
    "# Проверка: получение первого объекта.\n",
    "print(f'\\nПервый элемент:\\n\\t{dataset_train.__getitem__(0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6de0179c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина:\n",
      "\t5160\n",
      "\n",
      "Первый элемент:\n",
      "\t(array([   4.1528    ,   15.        ,    6.19327731,    0.98739496,\n",
      "        768.        ,    3.22689076,   35.34      , -119.08      ]), 1.301)\n"
     ]
    }
   ],
   "source": [
    "# Представление тестовой выборки в виде класса.\n",
    "dataset_test = MyDataset(X_test, y_test)\n",
    "\n",
    "# Проверка: вывод размерности.\n",
    "print(f'Длина:\\n\\t{dataset_test.__len__()}')\n",
    "\n",
    "# Проверка: получение первого объекта.\n",
    "print(f'\\nПервый элемент:\\n\\t{dataset_test.__getitem__(0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a54925f",
   "metadata": {},
   "source": [
    "#### 2. Оборачивание данных в DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "254e0ccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность батча признаков:\n",
      "\ttorch.Size([128, 8])\n",
      "\n",
      "Первый элемент батча признаков:\n",
      "\ttensor([   4.9643,   37.0000,    7.1064,    1.1489,   98.0000,    2.0851,\n",
      "          37.8500, -122.2400], dtype=torch.float64)\n",
      "\n",
      "Размерность батча таргетов:\n",
      "\ttorch.Size([128])\n",
      "\n",
      "Первый элемент батча таргетов:\n",
      "\t3.35\n"
     ]
    }
   ],
   "source": [
    "# Загрузчик данных обучающей выборки.\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=128, shuffle=True)\n",
    "\n",
    "# Проверка загрузчика.\n",
    "for batch, target in dataloader_train:\n",
    "    print(f'Размерность батча признаков:\\n\\t{batch.shape}')\n",
    "    print(f'\\nПервый элемент батча признаков:\\n\\t{batch[0]}')\n",
    "    print(f'\\nРазмерность батча таргетов:\\n\\t{target.shape}')\n",
    "    print(f'\\nПервый элемент батча таргетов:\\n\\t{target[0]}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6bfb0291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность батча признаков:\n",
      "\ttorch.Size([128, 8])\n",
      "\n",
      "Первый элемент батча признаков:\n",
      "\ttensor([   3.0673,   38.0000,    4.8810,    1.1161,  711.0000,    2.0142,\n",
      "          37.7300, -122.1400], dtype=torch.float64)\n",
      "\n",
      "Размерность батча таргетов:\n",
      "\ttorch.Size([128])\n",
      "\n",
      "Первый элемент батча таргетов:\n",
      "\t2.184\n"
     ]
    }
   ],
   "source": [
    "# Загрузчик данных тестовой выборки.\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=128, shuffle=True)\n",
    "\n",
    "# Проверка загрузчика.\n",
    "for batch, target in dataloader_test:\n",
    "    print(f'Размерность батча признаков:\\n\\t{batch.shape}')\n",
    "    print(f'\\nПервый элемент батча признаков:\\n\\t{batch[0]}')\n",
    "    print(f'\\nРазмерность батча таргетов:\\n\\t{target.shape}')\n",
    "    print(f'\\nПервый элемент батча таргетов:\\n\\t{target[0]}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6464ad5",
   "metadata": {},
   "source": [
    "#### 3. Архитектура нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d9122a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация класса нейросети:\n",
    "# - сеть состоит из двух блоков с постепенным понижением размерности;\n",
    "# - в каждом блоке используется функция активации \"LeakyReLU\", устойчивая к затуханию градиента;\n",
    "# - в конце каждого блока используется слой нормализации \"BatchNorm1d\" для повышения эффективности следующих слоёв;\n",
    "# - также в конце каждого блока используется слой \"Dropout\" для нивелирования эффекта переобучения;\n",
    "# - на выходе используется линейный слой без функции активации для прогноза непрерывной величины.\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(in_features=input_dim, out_features=input_dim*10)\n",
    "        self.ac_1 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.fc_2 = nn.Linear(in_features=input_dim*10, out_features=input_dim*8)\n",
    "        self.ac_2 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.bn_1 = nn.BatchNorm1d(num_features=input_dim*8)\n",
    "        self.do_1 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.fc_3 = nn.Linear(in_features=input_dim*8, out_features=input_dim*6)\n",
    "        self.ac_3 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.fc_4 = nn.Linear(in_features=input_dim*6, out_features=input_dim*4)\n",
    "        self.ac_4 = nn.LeakyReLU(negative_slope=0.1)\n",
    "        self.bn_2 = nn.BatchNorm1d(num_features=input_dim*4)\n",
    "        self.do_2 = nn.Dropout(0.25)\n",
    "        \n",
    "        self.fc_5 = nn.Linear(in_features=input_dim*4, out_features=1)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc_1(x)\n",
    "        x = self.ac_1(x)\n",
    "        x = self.fc_2(x)\n",
    "        x = self.ac_2(x)\n",
    "        x = self.bn_1(x)\n",
    "        x = self.do_1(x)\n",
    "        \n",
    "        x = self.fc_3(x)\n",
    "        x = self.ac_3(x)\n",
    "        x = self.fc_4(x)\n",
    "        x = self.ac_4(x)\n",
    "        x = self.bn_2(x)\n",
    "        x = self.do_2(x)\n",
    "        \n",
    "        x = self.fc_5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe52dea",
   "metadata": {},
   "source": [
    "#### 4. Сравнение сходимости различных методов оптимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3a83186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для обучения и валидации модели.\n",
    "def func_train(model, optimizer, epochs=1):\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for i, data_train in enumerate(dataloader_train):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_train = model(data_train[0].float())\n",
    "            loss_train = criterion(pred_train, data_train[1].float())\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 50 == 0:\n",
    "                model.eval()\n",
    "                \n",
    "                for _, data_test in enumerate(dataloader_test):\n",
    "                    pred_test = model(data_test[0].float())\n",
    "                    loss_test = criterion(pred_test, data_test[1].float())\n",
    "                \n",
    "                model.train()            \n",
    "            \n",
    "                print(\n",
    "                    f'Epoch {epoch + 1}/{epochs}\\t\\t' \\\n",
    "                    f'train loss {round(loss_train.item(), 2)}\\t\\t' \\\n",
    "                    f'train loss {round(loss_test.item(), 2)}.'\n",
    "                )\n",
    "\n",
    "    print('Training is finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af8c1c3",
   "metadata": {},
   "source": [
    "##### Метод оптимизации SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e14ed7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sgd = MyNet(X.shape[1])\n",
    "\n",
    "optimizer_sgd = SGD(model_sgd.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0e9f0b35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\t\ttrain loss 5.89\t\ttrain loss 4.4.\n",
      "Epoch 1/5\t\ttrain loss 5.37\t\ttrain loss 3.95.\n",
      "Epoch 1/5\t\ttrain loss 3.62\t\ttrain loss 4.39.\n",
      "Epoch 2/5\t\ttrain loss 3.09\t\ttrain loss 4.76.\n",
      "Epoch 2/5\t\ttrain loss 3.13\t\ttrain loss 2.85.\n",
      "Epoch 2/5\t\ttrain loss 3.87\t\ttrain loss 2.66.\n",
      "Epoch 3/5\t\ttrain loss 2.81\t\ttrain loss 2.13.\n",
      "Epoch 3/5\t\ttrain loss 2.57\t\ttrain loss 1.92.\n",
      "Epoch 3/5\t\ttrain loss 2.4\t\ttrain loss 1.08.\n",
      "Epoch 4/5\t\ttrain loss 2.33\t\ttrain loss 3.24.\n",
      "Epoch 4/5\t\ttrain loss 1.87\t\ttrain loss 2.48.\n",
      "Epoch 4/5\t\ttrain loss 1.83\t\ttrain loss 1.73.\n",
      "Epoch 5/5\t\ttrain loss 2.47\t\ttrain loss 1.01.\n",
      "Epoch 5/5\t\ttrain loss 1.29\t\ttrain loss 2.55.\n",
      "Epoch 5/5\t\ttrain loss 1.55\t\ttrain loss 2.47.\n",
      "Training is finished!\n",
      "Wall time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "func_train(model_sgd, optimizer_sgd, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93d2170",
   "metadata": {},
   "source": [
    "##### Метод оптимизации RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "21fd5a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_RMSprop = MyNet(X.shape[1])\n",
    "\n",
    "optimizer_RMSprop = RMSprop(model_RMSprop.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "add61761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\t\ttrain loss 4.66\t\ttrain loss 30.53.\n",
      "Epoch 1/5\t\ttrain loss 2.82\t\ttrain loss 2.95.\n",
      "Epoch 1/5\t\ttrain loss 2.59\t\ttrain loss 1.93.\n",
      "Epoch 2/5\t\ttrain loss 2.21\t\ttrain loss 2.21.\n",
      "Epoch 2/5\t\ttrain loss 1.45\t\ttrain loss 1.15.\n",
      "Epoch 2/5\t\ttrain loss 1.65\t\ttrain loss 1.23.\n",
      "Epoch 3/5\t\ttrain loss 1.79\t\ttrain loss 1.28.\n",
      "Epoch 3/5\t\ttrain loss 1.59\t\ttrain loss 1.64.\n",
      "Epoch 3/5\t\ttrain loss 1.41\t\ttrain loss 1.18.\n",
      "Epoch 4/5\t\ttrain loss 1.5\t\ttrain loss 1.06.\n",
      "Epoch 4/5\t\ttrain loss 1.86\t\ttrain loss 1.29.\n",
      "Epoch 4/5\t\ttrain loss 1.45\t\ttrain loss 1.39.\n",
      "Epoch 5/5\t\ttrain loss 1.61\t\ttrain loss 1.87.\n",
      "Epoch 5/5\t\ttrain loss 1.45\t\ttrain loss 0.8.\n",
      "Epoch 5/5\t\ttrain loss 2.06\t\ttrain loss 0.92.\n",
      "Training is finished!\n",
      "Wall time: 1.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "func_train(model_RMSprop, optimizer_RMSprop, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb12b6",
   "metadata": {},
   "source": [
    "##### Метод оптимизации Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "48f65316",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Adam = MyNet(X.shape[1])\n",
    "\n",
    "optimizer_Adam = Adam(model_Adam.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3e325fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\t\ttrain loss 7.46\t\ttrain loss 7.38.\n",
      "Epoch 1/5\t\ttrain loss 5.49\t\ttrain loss 6.04.\n",
      "Epoch 1/5\t\ttrain loss 4.96\t\ttrain loss 4.84.\n",
      "Epoch 2/5\t\ttrain loss 3.59\t\ttrain loss 5.01.\n",
      "Epoch 2/5\t\ttrain loss 2.87\t\ttrain loss 2.39.\n",
      "Epoch 2/5\t\ttrain loss 2.38\t\ttrain loss 1.59.\n",
      "Epoch 3/5\t\ttrain loss 2.21\t\ttrain loss 1.27.\n",
      "Epoch 3/5\t\ttrain loss 2.8\t\ttrain loss 1.65.\n",
      "Epoch 3/5\t\ttrain loss 1.36\t\ttrain loss 1.14.\n",
      "Epoch 4/5\t\ttrain loss 1.71\t\ttrain loss 1.22.\n",
      "Epoch 4/5\t\ttrain loss 1.68\t\ttrain loss 1.5.\n",
      "Epoch 4/5\t\ttrain loss 1.56\t\ttrain loss 1.62.\n",
      "Epoch 5/5\t\ttrain loss 1.69\t\ttrain loss 0.98.\n",
      "Epoch 5/5\t\ttrain loss 1.24\t\ttrain loss 1.91.\n",
      "Epoch 5/5\t\ttrain loss 1.77\t\ttrain loss 1.23.\n",
      "Training is finished!\n",
      "Wall time: 1.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "func_train(model_Adam, optimizer_Adam, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59284252",
   "metadata": {},
   "source": [
    "##### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0795081",
   "metadata": {},
   "source": [
    "В рамках решения данной задачи различные методы оптимизации демонстрировали различное качество метрики <code>MSE</code> от запуска к запуску. Однако оптимизатор <code>Adam</code> чаще остальных отличался в лучшую сторону меньшим переобучением.\n",
    "\n",
    "Также стоит отметить, что <code>Adam</code> в среднем работает чуть дольше, чем <code>SGD</code> и <code>RMSprop</code>, что может быть объяснено сложностью алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfdb6dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
